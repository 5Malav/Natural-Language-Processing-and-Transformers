{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Sentence Segmentation"
      ],
      "metadata": {
        "id": "r5yJNYjJRxwk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence segmentation (also called sentence boundary detection) is a key task in Natural Language Processing (NLP) where the goal is to divide a large block of text into individual sentences. This process is typically the first step in many NLP applications such as text parsing, information extraction, sentiment analysis, and machine translation.\n",
        "\n",
        "Why is Sentence Segmentation Important?\n",
        "Sentence segmentation helps to:\n",
        "\n",
        "Break down text into manageable chunks (sentences).\n",
        "Allow more accurate downstream NLP tasks such as tokenization, named entity recognition (NER), and dependency parsing.\n",
        "Improve the performance of models by ensuring they operate on clearly defined sentence boundaries.\n",
        "Challenges in Sentence Segmentation:\n",
        "While the task seems simple, it can be challenging due to:\n",
        "\n",
        "-> Abbreviations: Many abbreviations, such as \"Dr.\" or \"e.g.,\" can look like sentence boundaries but aren't. For example, \"Dr. Smith is here.\" should not be split after \"Dr.\".\n",
        "\n",
        "-> Punctuation: Full stops, exclamation points, and question marks might occur inside quotes, parentheses, or other constructs that do not mark sentence boundaries.\n",
        "\n",
        "-> Non-English Languages: Different languages have varying punctuation rules and structures, which makes segmentation more complex across languages.\n",
        "\n",
        "\n",
        "Common Approaches for Sentence Segmentation:-\n",
        "\n",
        "\n",
        "1.) Rule-based Methods\n",
        "\n",
        "Early sentence segmentation methods relied on rule-based approaches, where rules and regular expressions were defined to split text based on punctuation marks like periods, exclamation points, or question marks. However, this approach often failed to handle exceptions like abbreviations or titles (e.g., \"Dr.\" or \"Mr.\").\n",
        "\n",
        "Example rule:\n",
        "\n",
        "Split after a period if the next character is a space and the word after the period is not an abbreviation.\n",
        "\n",
        "2.) Machine Learning-based Methods\n",
        "\n",
        "Machine learning models can be trained to predict sentence boundaries using labeled data. Features might include:\n",
        "\n",
        "Punctuation marks (e.g., period, question mark, exclamation mark).\n",
        "Part-of-speech (POS) tags.\n",
        "Word sequences that often appear at sentence boundaries (e.g., \"Mr.\", \"Ms.\", \"Dr.\", \"etc.\").\n",
        "These models can be trained using supervised learning techniques such as Conditional Random Fields (CRFs) or Decision Trees.\n",
        "\n",
        "3.) Deep Learning-based Methods\n",
        "\n",
        "Deep learning approaches, particularly Recurrent Neural Networks (RNNs), LSTMs (Long Short-Term Memory), and Transformer-based models, are highly effective for sentence segmentation. These models learn to recognize sentence boundaries through context and can handle more complex scenarios like nested clauses or ambiguous punctuation.\n",
        "\n",
        "For example:\n",
        "\n",
        "A Bidirectional LSTM model could be trained to understand sentence boundaries from both directions (before and after a word).\n",
        "Transformers (e.g., BERT, GPT) have also been used in segmentation tasks, where they learn from context, making them more robust to complex sentence structures.\n",
        "\n",
        "4.) Pre-built Libraries and Tools\n",
        "\n",
        "Many popular NLP libraries have built-in sentence segmentation capabilities that use either rule-based or machine learning-based models. These tools often handle a wide range of edge cases.\n",
        "\n",
        "SpaCy: A popular NLP library that comes with pre-trained models capable of sentence segmentation out of the box.\n",
        "NLTK (Natural Language Toolkit): Another NLP library with a sentence tokenizer that can be used to split text into sentences.\n",
        "Stanza: A Python NLP package developed by Stanford that provides sentence segmentation models.\n",
        "## Hugging Face Transformers: we canfine-tune transformer models for specific NLP tasks, including sentence segmentation."
      ],
      "metadata": {
        "id": "sWoOseIGSOIY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "--hKNs0FRKdx"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc = nlp(u'This is the first sentence. This is another sentence. This is the last sentence.')\n",
        "\n",
        "for sent in doc.sents:\n",
        "    print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0s3BDcqERKbF",
        "outputId": "8c1b1200-ad9f-436d-fff8-6b9d7a1ae219"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is the first sentence.\n",
            "This is another sentence.\n",
            "This is the last sentence.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# doc.sents generatesn a sentence instead of holding them all in memory.\n",
        "# That's to save space because we can imagine, a document object can be\n",
        "# huge sometimes.\n",
        "# so we would not want all of this saved duplicated in memory.\n",
        "# Instead , we can iterate through the sentences.\n",
        "\n",
        "# so we can grab individual token but not sentences.\n"
      ],
      "metadata": {
        "id": "ULLCLfQBRKYY"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "list[doc.sents]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eS7Jo7QIRKVr",
        "outputId": "584d2825-2ab4-4aae-d830-d9cf54e98f0f"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list[<generator object at 0x794459619800>]"
            ]
          },
          "metadata": {},
          "execution_count": 143
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc2 = nlp(u'\"Management is doing things right; leadership is\\\n",
        " doing the right things.\" -Peter Drucker')\n",
        "\n",
        "for sent in doc2.sents:\n",
        "    print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Di4toAYCRKTB",
        "outputId": "a995a38a-169d-41ec-e2fa-50b9abe2dc27"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Management is doing things right; leadership is doing the right things.\"\n",
            "-Peter Drucker\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in doc2.sents:\n",
        "    print(sent)\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V33Xyd7vRKNX",
        "outputId": "c24ba1c1-45db-4753-c138-342ad6352f3f"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Management is doing things right; leadership is doing the right things.\"\n",
            "\n",
            "\n",
            "-Peter Drucker\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new rule.\n",
        "\n",
        "# Add a segmentation rule\n",
        "\n",
        "# Change segmentation rules"
      ],
      "metadata": {
        "id": "L_02LQyeRKKj"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Add a segmentation rule\n",
        "\n",
        "\n",
        "def set_custom_boudaries(doc):\n",
        "    for token in doc:\n",
        "        print(token)\n",
        "        print(token.i)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ob5o7R49RKHo"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "set_custom_boudaries(doc2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkmC7EYPRJ6W",
        "outputId": "47d1f9ef-715c-4cab-da79-ebd9134d08d5"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"\n",
            "0\n",
            "Management\n",
            "1\n",
            "is\n",
            "2\n",
            "doing\n",
            "3\n",
            "things\n",
            "4\n",
            "right\n",
            "5\n",
            ";\n",
            "6\n",
            "leadership\n",
            "7\n",
            "is\n",
            "8\n",
            "doing\n",
            "9\n",
            "the\n",
            "10\n",
            "right\n",
            "11\n",
            "things\n",
            "12\n",
            ".\n",
            "13\n",
            "\"\n",
            "14\n",
            "-Peter\n",
            "15\n",
            "Drucker\n",
            "16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SO new sentence will start after semicolon ;\n",
        "import spacy\n",
        "from spacy.language import Language\n",
        "\n",
        "@Language.component(\"custom_boundaries\")  # Register the component with a name\n",
        "def set_custom_boudaries(doc):\n",
        "    for token in doc[:-1]:\n",
        "        if token.text ==';':\n",
        "            doc[token.i+1].is_sent_start=True\n",
        "    return doc"
      ],
      "metadata": {
        "id": "2aCcfEjTRJ3k"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "ValueError: [E966] `nlp.add_pipe` now takes the string name of the registered component\n",
        "factory, not a callable component. Expected string, but got <function set_custom_boudaries\n",
        " at 0x79445bf83130> (name: 'None').\n",
        "\n",
        "- If you created your component with `nlp.create_pipe('name')`: remove nlp.create_pipe and\n",
        "call `nlp.add_pipe('name')` instead.\n",
        "\n",
        "- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string\n",
        "name instead, e.g. `nlp.add_pipe('textcat')`.\n",
        "\n",
        "- If you're using a custom component: Add the decorator `@Language.component`\n",
        " (for function components) or `@Language.factory` (for class components / factories)\n",
        " to your custom component and assign it a name, e.g. `@Language.component('your_name')`.\n",
        "  You can then run `nlp.add_pipe('your_name')` to add it to the pipeline.\n",
        "\n",
        "Solution:-\n",
        "\n",
        "The error message \"ValueError: [E966] nlp.add_pipe now takes the string name of the\n",
        " registered component factory, not a callable component\"\n",
        " indicates that you're trying to directly add the set_custom_boudaries\n",
        "  function to the spaCy pipeline using nlp.add_pipe. However,\n",
        "   spaCy now requires you to register custom components using decorators\n",
        "   and then add them by their registered name.\n",
        "\n",
        "The error happens because spaCy expects a string representing the registered\n",
        "component's name, not the function itself.\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "Z1D-4WkwYOx0",
        "outputId": "0f0bf963-63db-4b94-f8e4-229832fedeae"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nValueError: [E966] `nlp.add_pipe` now takes the string name of the registered component \\nfactory, not a callable component. Expected string, but got <function set_custom_boudaries\\n at 0x79445bf83130> (name: \\'None\\').\\n\\n- If you created your component with `nlp.create_pipe(\\'name\\')`: remove nlp.create_pipe and \\ncall `nlp.add_pipe(\\'name\\')` instead.\\n\\n- If you passed in a component like `TextCategorizer()`: call `nlp.add_pipe` with the string \\nname instead, e.g. `nlp.add_pipe(\\'textcat\\')`.\\n\\n- If you\\'re using a custom component: Add the decorator `@Language.component`\\n (for function components) or `@Language.factory` (for class components / factories) \\n to your custom component and assign it a name, e.g. `@Language.component(\\'your_name\\')`.\\n  You can then run `nlp.add_pipe(\\'your_name\\')` to add it to the pipeline.\\n\\nSolution:-\\n\\nThe error message \"ValueError: [E966] nlp.add_pipe now takes the string name of the\\n registered component factory, not a callable component\" \\n indicates that you\\'re trying to directly add the set_custom_boudaries\\n  function to the spaCy pipeline using nlp.add_pipe. However,\\n   spaCy now requires you to register custom components using decorators \\n   and then add them by their registered name.\\n\\nThe error happens because spaCy expects a string representing the registered \\ncomponent\\'s name, not the function itself.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 150
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3cXfF87ZXDtp",
        "outputId": "6f458bd7-3cfc-4f67-a488-2ba4403669dd"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Management is doing things right; leadership is doing the right things.\" -Peter Drucker"
            ]
          },
          "metadata": {},
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc2[:-1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "06xSsVYlXDnm",
        "outputId": "26983ca2-25e8-42b1-c2b0-65500e362f8d"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Management is doing things right; leadership is doing the right things.\" -Peter"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "nlp.add_pipe(\"custom_boundaries\",before='parser')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "KsEdIw2ZXDlP",
        "outputId": "e50c0667-29f8-4812-fe52-5fa8786ed378"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<function __main__.set_custom_boudaries(doc)>"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>set_custom_boudaries</b><br/>def set_custom_boudaries(doc)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/content/&lt;ipython-input-149-d4935e0ef5e7&gt;</a>&lt;no docstring&gt;</pre></div>"
            ]
          },
          "metadata": {},
          "execution_count": 153
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nlp.pipe_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RIDD2CK_XDi4",
        "outputId": "6e65a625-198b-43ab-c92e-f36f8e76a4b7"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['tok2vec',\n",
              " 'tagger',\n",
              " 'custom_boundaries',\n",
              " 'parser',\n",
              " 'attribute_ruler',\n",
              " 'lemmatizer',\n",
              " 'ner']"
            ]
          },
          "metadata": {},
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "doc4 = nlp(u'\"Management is doing things right; leadership is\\\n",
        " doing the right things.\" -Peter Drucker')"
      ],
      "metadata": {
        "id": "p616TU7KY5MN"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for sent in doc4.sents:\n",
        "    print(sent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8ekc3CwY5JZ",
        "outputId": "6bf2a3e7-8ffb-4bb3-be42-c0a028a41e93"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\"Management is doing things right;\n",
            "leadership is doing the right things.\"\n",
            "-Peter Drucker\n"
          ]
        }
      ]
    }
  ]
}