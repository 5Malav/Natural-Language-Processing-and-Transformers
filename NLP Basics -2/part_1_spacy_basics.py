# -*- coding: utf-8 -*-
"""Part - 1 Spacy Basics.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TyJrfO2ElmLLlVi4qxjgGFc58FXT02w9

# What is Spacy?

1.) Open Source Natural Language Processing Library

2.) Designed to effectively handle NLP tasks with the most efficient implementation of common algorithms.

3.) For many NLP tasks, Spacy onle has one implemented method, choosing the most efficient algorithm currently available.

4.) This means you often don't have the option to choose other algorithms.

# What is NLTK ?

1.) NLTK - Natural Language Toolkit is a very popular open source.

2.) Intially release in 2001, it is older than spacy(released in 2015)

3.) It provides many functionalities , but includes less efficient implementations.

# NLTK vs Spacy

1.) For many common NLP tasks, Spacy is much faster and more efficient, at the cost of the user not being able to choose algorithmic implementations.

2.) However, Spacy does not include pre-created models for some applications, such as sentiment analysis which is typically easier to perform with NLTK.

# What is Natural Language Processing ?

"Natural Language Processing(NLP) is an area of computer science and artificial intelligence concerned with the interactions between computers and human(natural) languages, in particular how to program computers to process and analyze large amounts of narural language data.

-> Often when performing analysis, lots of data is numerical , such as sales number, physical measurements, quantifiable categories.

-> Computers are very good at handling direct numerical information.

what to do about Text data?

-> Computer needs a specialized processing techniques in order to "understand" raw text data.

-> Text data is highly unstructured and can be in multiple languages!

-> Natural Language Processing attempts to use a veriety of techniques in order to create structure out of text data.

Example Use Cases:

1.) Classifying Emails as Spam vs Legitimate

2.) Sentiment Analysis if Text Movie Review

3.) Analyzing Trends from written customer feedback forms.

4.) Understanding text commands, "Hey Google, play this song"
"""

# import Spcay

import spacy

# Load language library

nlp = spacy.load("en_core_web_sm")
nlp

# create a document object

doc = nlp(u'Tesla and Bitcon prices are going up after election\
 currently at $84000')

# create a token from doc variable

for token in doc:
    print(token.text)

# POS = Part of speech

for token in doc:
    print(token.text,token.pos)


# In our output we see numbers like 95,89,96
# each of these number actually corresponds with a part
# of speech, like and adverb, a verb, a noun , a conjugation etc.
# to get name use token.pos_

print(" ")


for token in doc:
    print(token.text,token.pos,token.pos_)

# DEP = Syntactic dependency

for token in doc:
    print(token.text,token.pos,token.pos_,token.dep_)

# Pipe line object

nlp.pipeline

nlp.pipe_names

# Tokenization

# The very 1st step processing any text is to split it
# up all the component parts, that is the words and
# punctuation into tokens and these tokesn are annotated
# inside the doc object to contain descriptive information

doc2 = nlp(u'Tesla is not looking for startups anymore')
doc2

for token in doc2:
    print(token.text,token.pos_,token.dep_)

doc2 = nlp(u"Tesla isn't   looking for startups anymore")
doc2
for token in doc2:
    print(token.text,token.pos_,token.dep_)

doc2[0]

# So far we iterated all tokens.

# we can also take all of them using indexing.

doc[2].pos_

# syntactic dependency

doc2[0].dep_

"""## Additional Token Attributes

|Tag|Description|doc2[0].tag|
|:------|:------:|:------|
|`.text`|The original word text<!-- .element: style="text-align:left;" -->|`Tesla`|
|`.lemma_`|The base form of the word|`tesla`|
|`.pos_`|The simple part-of-speech tag|`PROPN`/`proper noun`|
|`.tag_`|The detailed part-of-speech tag|`NNP`/`noun, proper singular`|
|`.shape_`|The word shape â€“ capitalization, punctuation, digits|`Xxxxx`|
|`.is_alpha`|Is the token an alpha character?|`True`|
|`.is_stop`|Is the token part of a stop list, i.e. the most common words of the language?|`False`|
"""

# lemmas( The base form of the word)

print(doc2[4].text)
print(doc2[4].lemma_)

# Part of speech

print(doc[2].pos_)

print(doc2[4].tag_ +' || '+spacy.explain(doc2[4].tag_))

# Word shapes

print(doc[2].text+ ' || ' +doc[2].shape_)
print(doc2[5].text+ ' || ' +doc[5].shape_)

# Boolean value

print(doc2[0].text)

print(doc2[0].is_alpha)


print(doc2[5].text)

print(doc2[5].is_alpha)

"""# Spans

Large document objects can be hard to work with some times. A spane is a slice of Doc object in the form

Doc[start:stop]
"""

doc3 = nlp(u'Although commmonly attributed to John Lennon from his song "Beautiful Boy", \
the phrase "Life is what happens to us while we are making other plans" was written by \
cartoonist Allen Saunders and published in Reader\'s Digest in 1957, when Lennon was 17.')
doc3

# grab a span from it

life_quote=doc3[16:30]

life_quote

type(life_quote)
#spcay know type of span

type(doc3)

doc4 = nlp(u'This is the Spacy introduction. I tried to do as much practice as I could do. Next will do tokenization')

# Print each sentence

for sentence in doc4.sents:
    print(sentence)

doc4[3]

doc4[0].is_sent_start

doc4[15].is_sent_end