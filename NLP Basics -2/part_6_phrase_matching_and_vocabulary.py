# -*- coding: utf-8 -*-
"""Part - 6 Phrase Matching and Vocabulary.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_EVryK4WcSUOJ_cJeovc0PP_7lfWOmgt

# Phrase Matching and Vocabulary

Identify and label specific phrases that match patterns can be defined.

This can be as powerful as Regular expression where actual take parts of
speech into account for pattern search.

""
"""

import spacy

nlp =spacy.load('en_core_web_sm')

"""# Rule Based matching

Spacy offers a rule matching tool called Matcher, that allows to build
a library of token patterns then match those patterns against a doct
object to return a list of found matches, a very similiar idea to
regular expressions.

Using this any part of token, including text and annotations can be matched.
And we can add multiple pattern to the same matcher.

"
"""

from spacy.matcher import Matcher

matcher = Matcher(nlp.vocab)
matcher

"""## Other token attributes
Besides lemmas, there are a variety of token attributes we can use to determine matching rules:
<table><tr><th>Attribute</th><th>Description</th></tr>

<tr ><td><span >`ORTH`</span></td><td>The exact verbatim text of a token</td></tr>
<tr ><td><span >`LOWER`</span></td><td>The lowercase form of the token text</td></tr>
<tr ><td><span >`LENGTH`</span></td><td>The length of the token text</td></tr>
<tr ><td><span >`IS_ALPHA`, `IS_ASCII`, `IS_DIGIT`</span></td><td>Token text consists of alphanumeric characters, ASCII characters, digits</td></tr>
<tr ><td><span >`IS_LOWER`, `IS_UPPER`, `IS_TITLE`</span></td><td>Token text is in lowercase, uppercase, titlecase</td></tr>
<tr ><td><span >`IS_PUNCT`, `IS_SPACE`, `IS_STOP`</span></td><td>Token is punctuation, whitespace, stop word</td></tr>
<tr ><td><span >`LIKE_NUM`, `LIKE_URL`, `LIKE_EMAIL`</span></td><td>Token text resembles a number, URL, email</td></tr>
<tr ><td><span >`POS`, `TAG`, `DEP`, `LEMMA`, `SHAPE`</span></td><td>The token's simple and extended part-of-speech tag, dependency label, lemma, shape</td></tr>
<tr ><td><span >`ENT_TYPE`</span></td><td>The token's entity label</td></tr>

</table>
"""

# Find a pattern.

#


# SolarPower
pattern_1 = [{'LOWER':'solarpower'}]

#solar-power
pattern_2 = [{'LOWER':'solar'},{'IS_PUNCT':True},{"LOWER":'power'}]

# Solar Power
pattern_3 = [{'LOWER':'solar'},{'LOWER':'power'}]

matcher.add('SolarPower',[pattern_1,pattern_2,pattern_3])

doc = nlp(u'The Solar Power industry is boolimg in India.As electricity\
through solarpower is cheap.Government also provide money for solar-power\
equipment ')

matches= matcher(doc)
print(matches)

# String id, start,stop

# matcher returns a list of tuple. Each tupel contains an ID for the match,
# with start and end tokens that map to the span[start:end]

for match_id,start,end in matches:
    string_id = nlp.vocab.strings[match_id] # get string representation
    span = doc[start:end]                  # get the matched span
    print(match_id,string_id,start,end,span.text)

# remove a pattern

matcher.remove('SolarPower')

"""This found both two-word patterns, with and without the hyphen!

The following quantifiers can be passed to the `'OP'` key:
<table><tr><th>OP</th><th>Description</th></tr>

<tr ><td><span >\!</span></td><td>Negate the pattern, by requiring it to match exactly 0 times</td></tr>
<tr ><td><span >?</span></td><td>Make the pattern optional, by allowing it to match 0 or 1 times</td></tr>
<tr ><td><span >\+</span></td><td>Require the pattern to match 1 or more times</td></tr>
<tr ><td><span >\*</span></td><td>Allow the pattern to match zero or more times</td></tr>
</table>

"""

pattern1 = [{'LOWER':'solarpower'}]

pattern2 = [{'LOWER':'solar'},{'IS_PUNCT':True,'OP':'*'},{'LOWER':'power'}]

matcher.add('SolarPower',[pattern1,pattern2])

doc2 = nlp(u'Solar--power is solarpower yeee! solarpower is next big thing')

matches = matcher(doc2)
matches

for match_id,start,end in matches:
    string_id=nlp.vocab.strings[match_id] # get string representation
    span = doc[start:end]
    print(match_id,string_id,start,end,span.text)

"""# Phrase Matching"""

from spacy.matcher import PhraseMatcher

matcher = PhraseMatcher(nlp.vocab)

#Specify encoding: We change the open() function to explicitly
#specify the file's encoding.
#The encoding='latin-1' argument tells Python to interpret the
#file using the 'latin-1' encoding.

with open('/content/reaganomics.txt',encoding='latin-1') as f:
    doc3= nlp(f.read())

phrase_list = ['voodoo economics', 'supply-side economics', \
               'trickle-down economics', 'free-market economics']

# Next, convert each phrase to a Doc object:
phrase_patterns = [nlp(text) for text in phrase_list]

# Pass each Doc object into matcher (note the use of the asterisk!):
matcher.add('VoodooEconomics', None, *phrase_patterns)

# Build a list of matches:
matches = matcher(doc3)

matches

for match_id,start,end in matches:
    string_id=nlp.vocab.strings[match_id] # get string representation
    span = doc3[start:end]
    print(match_id,string_id,start,end,span.text)

# for more context of token add and subtract from start and end

for match_id,start,end in matches:
    string_id=nlp.vocab.strings[match_id] # get string representation
    span = doc3[start-10:end+10]
    print(match_id,string_id,start,end,span.text)
    print("\n")









