{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Stemming\n",
        "\n",
        "-> When we search text for a certain keyword, it helps if the search return variations of the word.\n",
        "\n",
        "-> For example, searching for  \"boat\" might also return \"boats\" and \"boating\". Here \"boat\" would be the stem for [boat, boater, boating, boats]\n",
        "\n",
        "-> Stemming is a somewhat crude method for cataloging related words; it essentially chops off letters from the end until the stem is reached.\n",
        "\n",
        "-> This works fairly well in most cases, but unfortunately English has many exceptions where a more sphisticated process required.\n",
        "\n"
      ],
      "metadata": {
        "id": "edTkXtQyjcrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Porters' Algorithm\n"
      ],
      "metadata": {
        "id": "Qi35OIHYuVA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "-> One of the most common and effective stemming tools is\n",
        "Porter's Algorithm developed by Martin Porter in 1980.\n",
        "\n",
        "-> The algorithm emoploys 5 phases  of word reduction,\n",
        "each with its own set of mapping rules.\n",
        "\n",
        "-> In the 1st phase, simple suffix mapping rules are defined such as:\n",
        "\n",
        "S1 to S2:\n",
        "\n",
        "1.) SSES -> SS\n",
        "2.) IES -> I\n",
        "3.) SS -> SS\n",
        "4.) S ->\n",
        "\n",
        "\n",
        "\n",
        "word to stem:\n",
        "\n",
        "caresses -> caress\n",
        "ponies -> poni\n",
        "ties -> ti\n",
        "caress -> caress\n",
        "cats -> cat\n",
        "\n",
        "-> SO from the given set of stemming rules only one rule is applied,\n",
        " based off the longest suffix, S1.\n",
        "\n",
        "-> Thus caresses reduces to caress but not to cares.\n",
        "That way there is not confusion and mixing up different\n",
        "types of words to the wrong stem.\n",
        "\n",
        "-> There are some more sophisticated phases consider\n",
        "the length/ complexity of the word before applying a rule.\n",
        "For example,\n",
        "\n",
        "S1 --> S2\n",
        "(m>0) ATIONAL -> ATE\n",
        "(m>0) EED -> EE\n",
        "\n",
        "\n",
        "WORD --> stem\n",
        "\n",
        "relational -> relate\n",
        "national -> national\n",
        "\n",
        "agreed-> agree\n",
        "feed -> feed\n",
        "\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "FdMoz93Tgsk_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 192
        },
        "outputId": "6aade39e-ccfe-4a04-a38d-3bdd42e88f2f"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n\\n-> One of the most common and effective stemming tools is \\nPorter's Algorithm developed by Martin Porter in 1980.\\n\\n-> The algorithm emoploys 5 phases  of word reduction, \\neach with its own set of mapping rules.\\n\\n-> In the 1st phase, simple suffix mapping rules are defined such as:\\n\\nS1 to S2:\\n\\n1.) SSES -> SS\\n2.) IES -> I\\n3.) SS -> SS\\n4.) S -> \\n\\n\\n\\nword to stem:\\n\\ncaresses -> caress\\nponies -> poni\\nties -> ti\\ncaress -> caress\\ncats -> cat\\n\\n-> SO from the given set of stemming rules only one rule is applied,\\n based off the longest suffix, S1.\\n\\n-> Thus caresses reduces to caress but not to cares. \\nThat way there is not confusion and mixing up different \\ntypes of words to the wrong stem.\\n\\n-> There are some more sophisticated phases consider \\nthe length/ complexity of the word before applying a rule.\\nFor example,\\n\\nS1 --> S2\\n(m>0) ATIONAL -> ATE\\n(m>0) EED -> EE\\n\\n\\nWORD --> stem\\n\\nrelational -> relate\\nnational -> national\\n\\nagreed-> agree\\nfeed -> feed\\n\\n\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Snowball"
      ],
      "metadata": {
        "id": "lqEcf_h8xfGZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "\n",
        "Snowball is the name of a stemming language also developed by Martin Porter.\n",
        "\n",
        "The algorithm used here is more accurately called the \"English Stemmer\"\n",
        "or \"Porter2 Stemmer\"\n",
        "\n",
        "If offers a slight improvement over the original Porter Stemmer, both\n",
        "in logic and speed.\n",
        "\n",
        "\n",
        "\"\"\"\n",
        "\n"
      ],
      "metadata": {
        "id": "eysDe_F9gsiZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "ebc48b5c-f40e-4f9f-d024-367143eaaab2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n\\nSnowball is the name of a stemming language also developed by Martin Porter.\\n\\nThe algorithm used here is more accurately called the \"English Stemmer\"\\nor \"Porter2 Stemmer\"\\n\\nIf offers a slight improvement over the original Porter Stemmer, both \\nin logic and speed.\\n\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk"
      ],
      "metadata": {
        "id": "rUfUw6CEgsgP"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.porter import PorterStemmer"
      ],
      "metadata": {
        "id": "X6ca58xVgsde"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p_stem= PorterStemmer()"
      ],
      "metadata": {
        "id": "r-S8DL3XgsbY"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words = [\"run\",\"runner\",\"ran\",\"runs\",\"Love\",\"Malav\",\"Maya\",\"Mrugesh\",\\\n",
        "         \"fairly\",\"easily\",\"notably\"]"
      ],
      "metadata": {
        "id": "YYHMOb2YgsYl"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "    print(word + \"--->\"+p_stem.stem(word))\n",
        "    print(\"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "XsSQAxLdgsTS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07352ac5-0e7a-4b20-b0ed-8dcdb989f285"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run--->run\n",
            "\n",
            "\n",
            "runner--->runner\n",
            "\n",
            "\n",
            "ran--->ran\n",
            "\n",
            "\n",
            "runs--->run\n",
            "\n",
            "\n",
            "Love--->love\n",
            "\n",
            "\n",
            "Malav--->malav\n",
            "\n",
            "\n",
            "Maya--->maya\n",
            "\n",
            "\n",
            "Mrugesh--->mrugesh\n",
            "\n",
            "\n",
            "fairly--->fairli\n",
            "\n",
            "\n",
            "easily--->easili\n",
            "\n",
            "\n",
            "notably--->notabl\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem.snowball import SnowballStemmer"
      ],
      "metadata": {
        "id": "5cVTeLrfgrNy"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_stem = SnowballStemmer(language='english')"
      ],
      "metadata": {
        "id": "A549kKE6grLT"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for word in words:\n",
        "    print(word + \"--->\"+s_stem.stem(word))\n",
        "    print(\"\\n\")\n",
        "\n"
      ],
      "metadata": {
        "id": "BLE4dXg8grIo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6144e83f-b817-4458-d982-cc7b564c1f46"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "run--->run\n",
            "\n",
            "\n",
            "runner--->runner\n",
            "\n",
            "\n",
            "ran--->ran\n",
            "\n",
            "\n",
            "runs--->run\n",
            "\n",
            "\n",
            "Love--->love\n",
            "\n",
            "\n",
            "Malav--->malav\n",
            "\n",
            "\n",
            "Maya--->maya\n",
            "\n",
            "\n",
            "Mrugesh--->mrugesh\n",
            "\n",
            "\n",
            "fairly--->fair\n",
            "\n",
            "\n",
            "easily--->easili\n",
            "\n",
            "\n",
            "notably--->notabl\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# There is some set of algorithmic rules  that these stemmers are\n",
        "# following to try to reduce down these words to some sort of\n",
        "# root idea or root word.\n",
        "\n"
      ],
      "metadata": {
        "id": "c5_7po_UgrGo"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "words=['Adventure','Harmony','Breeze','Enigma','Velvet','Radiance',\\\n",
        "       'Whimsy','Infinite','Reverie','Cascade']\n",
        "\n",
        "for word in words:\n",
        "    print(word + \" ------->\"+p_stem.stem(word))\n",
        "\n",
        "print(\" \")\n",
        "\n",
        "for word in words:\n",
        "    print(word + \" ------->\"+s_stem.stem(word))"
      ],
      "metadata": {
        "id": "Tf2DkDuSgrDu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fd328d9-bee3-45d5-87e4-71112c42c0b4"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Adventure ------->adventur\n",
            "Harmony ------->harmoni\n",
            "Breeze ------->breez\n",
            "Enigma ------->enigma\n",
            "Velvet ------->velvet\n",
            "Radiance ------->radianc\n",
            "Whimsy ------->whimsi\n",
            "Infinite ------->infinit\n",
            "Reverie ------->reveri\n",
            "Cascade ------->cascad\n",
            " \n",
            "Adventure ------->adventur\n",
            "Harmony ------->harmoni\n",
            "Breeze ------->breez\n",
            "Enigma ------->enigma\n",
            "Velvet ------->velvet\n",
            "Radiance ------->radianc\n",
            "Whimsy ------->whimsi\n",
            "Infinite ------->infinit\n",
            "Reverie ------->reveri\n",
            "Cascade ------->cascad\n"
          ]
        }
      ]
    }
  ]
}