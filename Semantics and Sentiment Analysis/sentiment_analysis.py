# -*- coding: utf-8 -*-
"""Sentiment Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1hKjkVBX69_gwD86oHS7uuwt7JAvfjL4t

VADER ( Valence Aware Dictionary for Sentiment Reasoning)
is a model used for text sentiment analysis that is sensitive to
both polarity (positive/ negative) and intensity(strength) of emotion

Primarily , VADER sentiment analysis relies on a dictionary which maps
lexical features to emotion insensities called sentiment scores.

The sentiment score of a text can be obtained by summing up the intensity
of each word in the text.

For example, words like "love" , "like" , "enjoy" , "happy" all convey
a positive sentiment.

VADER is intelligent enough to understand basic context of these words,
such as "did not love" as a negative sentiment.

It also understand capitalization and punctuation such as "LOVE!!!"

Sentiment Analysis on raw text is always challenging however, due to
a variety of possible factors:
Positive and Negative sentiment in the same text data.

Sarcasm using positive words in a negative way.

""
"""

import nltk

nltk.download("vader_lexicon")

from nltk.sentiment.vader import SentimentIntensityAnalyzer

sid = SentimentIntensityAnalyzer()
sid

# Vader Sentiment Intensity Analyzer does is it simply takes in the
# string and returns a dictionary of scores in 4 categories.

# Negative, neutral, positive, and then a compound score which is
# computed by normalizing the negative, neutral and positive scores.

a = "This is a good movie"

sid.polarity_scores(a)

b="I can't find my keys anywhere."

sid.polarity_scores(b)

c = "I love the new design of the website, but it's really slow to load."

sid.polarity_scores(c)

d = "I enjoy going for morning runs, but the weather has been too cold lately."

sid.polarity_scores(d)

# Compound score above 0 indicates positive score,
# Compound score below 0 indicates negative score.

import pandas as pd

data =  pd.read_csv("/content/amazonreviews.tsv",sep="\t")
data.head()

data['label'].value_counts()

data.info()

data.isna().sum()

data.dropna(inplace=True)

# drop empty white space values if any

blanks=[]
for i,lb,rv in data.itertuples():

    # index, label, review
    if type(rv) == str:
        if rv.isspace():
            blanks.append(i)
blanks

data.drop(blanks,inplace=True)

data.iloc[0]['review']

#data['review'][0]

sid.polarity_scores(data.iloc[0]['review'])

# add new column
data['scores']= data['review'].apply(lambda review: sid.polarity_scores(review))
data.head()

# new column compound
data['compound']= data['scores'].apply(lambda d:d['compound'])
data.head()

data['comp_score']= data['compound'].apply(lambda score:"pos" if score>=0 else "neg")

data.head()

data.tail()

from sklearn.metrics import confusion_matrix,classification_report

confusion_matrix(data['label'],data['comp_score'])

report=classification_report(data['label'],data['comp_score'],output_dict=True)
report

report= pd.DataFrame(report).transpose()
report