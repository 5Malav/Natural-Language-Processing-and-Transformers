# -*- coding: utf-8 -*-
"""Feature extraction from Text- Pipeline.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1DsodVwXKate8LDX3OwT6n32NyelK6s77
"""

# import libraries

import numpy as np
import pandas as pd

from sklearn.model_selection import train_test_split

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfTransformer
from sklearn.feature_extraction.text import TfidfVectorizer

from sklearn.svm import LinearSVC
from sklearn.pipeline import Pipeline

from sklearn.metrics import confusion_matrix,classification_report

# Load the data
data= pd.read_csv("/content/smsspamcollection.tsv",sep="\t")
data.head()

# Previously we did classification using length and pucnt columns
# now lets use messages.

# check for missing values

data.isnull().sum()

data['label'].value_counts()

X = data['message']
X.head()

y = data['label']
y.head()

# Split the data in training and test set

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.33,\
                                               random_state=42)

# Count Vectorization

# So text pre-processing,tokenizing, and the ability to filter out
# stop words are all included in count vectorizer
# which builds a dictionary of features and transforms documents to
# feature vectors.

count_vectorizer =CountVectorizer()

# Fit the vectorizer to the data(build a vocab,count the number of words)

#count_vectorizer.fit(X_train)

#X_train_counts = count_vectorizer.transform(X_train)

# Transform the original text message to the vector.

X_train_counts=count_vectorizer.fit_transform(X_train)
X_train_counts

# to view sparse matrix.

X_train.shape

# So 3733 messages in X_train and across all messages there are 7082 unique
# words

X_train_counts.shape

# Next step is transform the counts to frequencies with TF-IDF.
# Then combine the steps with TF-IDF vectorizer train classifer and
# build pipeline

tfidf_transformer= TfidfTransformer()

X_train_tfidf=tfidf_transformer.fit_transform(X_train_counts)

X_train_tfidf.shape

vectorizer= TfidfVectorizer()

# this combine the both Count Vectorization and TDIDF transformation
X_train_tfidf = vectorizer.fit_transform(X_train)

# train a classifier

model = LinearSVC()
model.fit(X_train_tfidf,y_train)

# Only training set has been vectorized into a full vocabulary.

# In order to perform an analysis on our test set, we would actually
# have to then repeat all these same procedures.

# it can be time wasting because if we have a long process.

# we can use pipeline class that behaves like a compound classifier.
# It can perform both vectorization and classification.

# So instead of doing fit_transform and count vectorization on test data
# we can combine all steps in one single pipeline.

pipeline= Pipeline([('tfidf',TfidfVectorizer()),
                    ('model',LinearSVC())])

# fit data in pipeline

pipeline.fit(X_train,y_train)

pred= pipeline.predict(X_test)
pred

cm = confusion_matrix(y_test,pred)
cm

report=classification_report(y_test,pred,output_dict=True)
report

report= pd.DataFrame(report).transpose()
report

# model gave better result with vectorization

# accuracy is 98%.

pipeline.predict(['My name is malav joshi. How are you?'])

pipeline.predict(['Please provide your details for lottery.\
                    please text "WINNER" '])